# 250911
## ✅TO-DO
- CBOW 구조에서 원-핫 벡터와 가중치 W와 행렬곱을 진행한 벡터의 평균을 구하는 걸까? -> 답 찾아보기
- ✅위키독스 09-03
- 위키독스 09-04
- 위키독스 09-05
- 위키독스 09-06
- 밑딥시 ch3
- ✅슬랙 진행 사안 작성

## 📌Today I Learned
### negative sampling 
- 주변 단어가 아닌 다른 단어들을 단어 집합에서 random으로 가져옴
- 주변 단어: positive
- 랜덤으로 샘플링된 단어: negative

### SGNS vs skip-gram
- skip-gram은 중심 단어를 통해 주변 단어들에 대한 확률 예측한다.
- SGNS는 skip-gram을 negative sampling을 통해 효율화된거다. 
    - 예측값: 중심단어와 주변단어의 내적값
    - 예측값을 loss func에 넣고 역전파를 통해 임베딩 테이블 업데이트
    - 임베딩 테이블을 두개(중심단어, 주변단어(random으로 샘플링한 단어 포함))

## 💡 회고 / 인사이트
- 생각보다 위키독스 실습이 시간이 걸린다. ㅇㅅㅇ... 실습하면서 오류가 발생하고, 오류에 대해서 알아보다보니,,,
### 계획 감각
- 아직 내가 어느 정도의 시간에 얼마만큼의 태스크를 수행할 수 있는지에 대한 감각이 없다. 그래서 투두 짜는 게 쉽지 않다. 그래도 하다보면 감이 잡히겠져. 

## 💥 트러블슈팅
### 코랩에서 gensim을 통해 google에서 제공하는 Word2Vec 모델 로드하기
- 위키독스에서는 urllib로 google에서 제공하는 Word2Vec 모델을 다운받고 path를 지정해서 모델을 로드했다. 그런데 더이상 해당 url에 모델이 존재하지 않아서 gensim에서 제공하는 준비된 모델을 다운로드할 수 있는 기능 ```gensim.downloader```을 이용했다.
- url 문제 없이 자동으로 다운로드, 캐시로 저장된다. 모델 로드에 시간이 5분정도 소요됐다.
- 나중에 내가 직접 Word2Vec을 재구현하고 성능 평가할 때 비교하면 좋을 것 같다. 
    - gensim, google Word2vec

## 🍩내일 할 일
- 위키독스 09-04
- 위키독스 09-05
- 위키독스 09-06
- 밑딥시 ch3
- CBOW 구조에서 원-핫 벡터와 가중치 W와 행렬곱을 진행한 벡터의 평균을 구하는 걸까? -> 답 찾아보기
- 논문 Abstract, Conclusion 읽어보기
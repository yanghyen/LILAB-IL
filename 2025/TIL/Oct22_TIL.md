# 251022
## ✅TO-DO
- ✅언어에이전트 발표 회고 작성 
- SGNS 결과 평가 및 해석
    - 트러블슈팅 작성 
- ✅hs 실험 
- 평가지표 정리 

## 📌Today I Learned
### 평가 데이터셋
### Human-annotated similarity scores data
- WordSim-353, SimLex-999, MEN
#### WordSim-353
- 단어유사도: 의미적/관련성 유사도
- 353쌍의 영어 단어 쌍과 사람들이 매긴 유사도 점수로 구성됨
- 유사성 외에 관련성까지 포괄
- coffee와 cup 관련성 높음
#### SimLex-999
- 단어유사도: 순수 의미적 유사도
- 999쌍의 단어 쌍과 점수로 구성
- 유사성만 평가하도록 설계
- cat과 dog는 유사성 높고, coffee와 cup은 유사성 낮음
#### 평가 방법
1.  평가할 단어 쌍에 대해 모델이 학습한 임베딩 추출
2. 두 벡터 간의 코사인 유사도 계산 -> 모델의 유사도 점수
3. 데이터셋에 있는 인간이 부여한 유사도 점수와 비교
4. 정확도 측정: 두 점수 간의 순위 일치도 측정을 위해 -> 스피어만 순위 상관계수 사용
- -1 ~ +1 값

### Google Analogy
- 단어관계: 유추 정확도
- 약 2만개의 유추 문제 쌍으로 구성
- A:B :: C:D (king:man :: queen:woman)
- 의미적 유추와 문법적 유추 평가
#### 평가 방법
- 단어 임베딩의 선형성, 벡터 공간에서 의미적/문법적 관계가 평행 이동으로 평행되는지 측정
1. 벡터계산: x = v_B - v_A + v_C를 사용해 정답 벡터 v_D에 가장 가까운 벡터 계산
2. 가장 가까운 단어 찾기: x벡터와 사전 내의 모든 단어 벡터 v_w 사이의 코사인 유사도 측정
3. 정확도 측정: 코사인 유사도가 가장 높은 단어를 예측 단어로 선택
- 정확도: 예측단어가 실제 정답단어와 일치하는 유추 문제의 비율 

### 허프만 트리
- 텍스트 압축을 위해 쓰이는 방법
- 원본 데이터에서 자주 출현하는 문자는 적은 비트의 코드로 변환해 표현
- 출현 빈도가 낮은 문자는 많은 비트의 코드로 변환하여 표현
- -> 전체 데이터를 표현하는데 필요한 비트 수를 줄임
- 출현 빈도가 가장 높은 문자를 루트 노드에 두고 00부여, 가장 아래에 있는 문자는 011011부여 

## 💡 회고 / 인사이트
### 언어에이전트 in-progress 발표 회고
- 한 마디 평: 주관적 해석X 객관적 해석O 
- 논문의 결과를 반박하는 듯한 실험 결과를 발표하기 위해선 객관적 지표를 통해 증명해야 한다. 논문과 결과가 다른 이유를 명확히 해야 한다. 내 실험 설계 혹은 코드가 잘못 됐다 or 논문이 틀렸다.
- 이때 논문이 틀렸다는 것을 말하기 위해선 굉장히 심사숙고해야 한다. 
- p-value처럼 객관적인 지표들을 정리하자. Word2Vec 평가지표들도 정리하자.
- final 발표 때는 이번 실험의 오류를 설명하고, 객관적 지표를 활용한 여러 실험도 해보고, 논문에 있는 실험을 직접 구현해서 비교해보자.

## 💥 트러블슈팅

## 🍩내일 할 일 
- SGNS 결과 평가 및 해석
    - 트러블슈팅 작성 
- hs 결과 평가 및 해석 
- 평가지표 정리 
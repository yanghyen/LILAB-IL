# 250923
## ✅TO-DO
- ✅언어에이전트 발표1 논문 훑기 
- ✅CBOW 재구현 및 실험 
- ✅Skip-gram 재구현 및 실험 

## 📌Today I Learned
### AVSR
- 노이즈가 있는 환경에선 음성 파일만으로 의미 파악하기가 어려워서 visual data까지 input data로 넣게 됐다. 그런데 이렇게 되면 토큰수가 너무 늘어나서 연산량이 늘어난다. 그러면 cost가 확 뛴다.
- 이런 문제를 해결하기 위해 도입된 게 MMS-LLaMA이다. 총 3가지 구조를 통해 보완했다.
1. early AV-fusion Module
- 먼저 audio와 visual data의 통합을 llm에 입력하기 전에 진행한다. 이를 통해 거대 llm에 입력되는 토큰수가 절반으로 줄어든다.
2. AV Q-Former
- 토큰수가 절반으로 줄어도 text token 스케일보다 훨씬 크기 때문에 AV Q-Former로 text token 스케일까지 압축한다. 
- 기존 Q-Former와의 차별점은 길이에 따라 쿼리를 동적으로 할당한다는 점이다. 말이 길수록 그 속의 단어수는 많으니까.
3. Speech Rate Predictor
- 이때 발화 속도도 굉장히 중요한 요소이다. 발화 속도가 빠른 사람은 발화 속도가 느린 사람보다 시간은 짧지만 그 속의 단어수는 더 많기 때문이다.
- 그래서 발화 속도를 예측해서 그에 따라 빠른 사람에겐 더 많은 토큰을 할당하도록 전략을 다듬었다.

## 💡 회고 / 인사이트
### 자세 이슈
- 점점 목이랑 어깨가 아프다,, 

## 💥 트러블슈팅
### CBOW 재구현 회고
- nltk에서 제공하는 brown dataset으로 학습하니까 데이터셋이 확실히 적다. 작은 데이터셋에서 subsampling과 negative sampling 했더니 결과가 이상했다. 
- 그래서 text8로 데이터셋을 바꿨다.

## 🍩내일 할 일 
- 언어에이전트 발표1 논문 정리
- CBOW 재구현 결과 비교 및 보완
- Skip-gram 재구현 결과 비교 및 보완
# 250910
## ✅TO-DO
- ✅Word2Vec2 논문 끝까지 읽기 
- ✅위키독스 09-01
- ✅위키독스 09-02
- 위키독스 09-03
- 밑딥시 ch3

## 📌Today I Learned
### CBOW
- CBOW는 원-핫 벡터가 입력값으로 들어오면 초기에는 랜덤으로 지정된 가중치 W와 행렬곱 연산한다. 그후 결과 벡터를 평균을 내준 뒤, 두번째 가중치 W'와 행렬곱 연산한다. 결과 벡터를 softmax를 통해 총 합이 1인 연속적인 0~1 사이의 실수로 나타낸다. 이게 손실함수 계산에 들어갈 score vector가 된다. 
- 여기서 Negative Sampling이나 Hierarchical Softmax를 쓰면 softmax 단계가 바뀌는 것 

## 💡 회고 / 인사이트
### CBOW 구조에서 원-핫 벡터와 가중치 W와 행렬곱을 진행한 벡터의 평균을 구하는 걸까?
- 

## 💥 트러블슈팅
### 논문에 익숙하지 않으니...
- 논문에 익숙하지 않아서 냅다 논문부터 읽으니까 집중도 안되고 오랫동안 읽어내도 이해가 안됐다.
1. 위키독스로 큰 그림을 그리기
2. 논문의 Abstract, 그림, Conclusion만 읽기
3. 실험 결과표와 그림
4. 수식/세부 설명
5. 코드 직접 구현 및 실험 

## 🍩내일 할 일
- CBOW 구조에서 원-핫 벡터와 가중치 W와 행렬곱을 진행한 벡터의 평균을 구하는 걸까? -> 답 찾아보기
- 위키독스 09-03
- 위키독스 09-04
- 밑딥시 ch3
- 밑딥시 ch4
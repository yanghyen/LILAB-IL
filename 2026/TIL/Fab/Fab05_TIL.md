# 260205
## ğŸ”¥ChallengeğŸ’§
- ğŸ”¥ì¼ì° ì¶œê·¼: 09:30
- 1ì¼1ë…¼ë¬¸: Learning to Instruct for Visual Instruction Tuning, I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts
- 1ì¼1êµ¬í˜„: cross-lingual RAG (https://arxiv.org/abs/2505.10089)
  - https://github.com/amazon-science/XRAG?utm_source=chatgpt.com 

## âœ…TO-DOğŸ 
- ì§„í–‰ì‚¬ì•ˆ ì—…ë¡œë“œ 
- âœ…Transformers) ê°œë… ê³µë¶€ decoder êµ¬ì¡° ì•„ì´íŒ¨ë“œ
- ğŸ Transformers) ì½”ë“œë‘ ë¹„êµ 
- ë””ë™) â€œThink Twiceâ€: Perspective-Taking Improves LLMsâ€™ Theory-of-Mind Capabilities â€“ ACL 2024 ì½ê¸° 
- ELMo) í•™ìŠµ ë¶ˆê°€ ì›ì¸ ì°¾ê¸° 

## ğŸ“ŒToday I Learned
### ëª¨ë¸ ë³„ íŠ¹ì„± ì°¾ì•„ë³´ê¸°


## ğŸ’¡ íšŒê³  / ì¸ì‚¬ì´íŠ¸

## ğŸ’¥ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…


## ğŸ©ë‚´ì¼ í•  ì¼ 
- ì§„í–‰ì‚¬ì•ˆ ì—…ë¡œë“œ 
- ğŸ Transformers) ì½”ë“œë‘ ë¹„êµ 
- ë””ë™) ì‹¤í—˜ ì„¸ì›Œì„œ ì§„í–‰í•´ë³´ê¸°
- ELMo) í•™ìŠµ ë¶ˆê°€ ì›ì¸ ì°¾ê¸° 